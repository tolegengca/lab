---
# Based on the official Airflow Docker Compose file
# https://airflow.apache.org/docs/apache-airflow/stable/docker-compose.yaml
version: '3.8'

x-airflow-common: &airflow-common
  image: apache/airflow:2.9.2-python3.12
  env_file:
    - .env
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./requirements.txt:/requirements.txt
  networks:
    - airflow_network # All services on this network
  depends_on:
    - postgres-airflow-db
  entrypoint: /bin/bash
  command:
    - -c
    - |
      pip install -r /requirements.txt;
      airflow db init;
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true;
      (airflow webserver & airflow scheduler)

services:
  # Database for Airflow Metadata
  postgres-airflow-db:
    image: postgres:13
    container_name: postgres-airflow-db
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    networks:
      - airflow_network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      timeout: 5s
      retries: 5

  # ----- ETL TARGET DATABASE -----
  # This is the separate Postgres DB for our ETL pipeline
  postgres-etl-target:
    image: postgres:15
    container_name: postgres-etl-target
    ports:
      - "5433:5432" # Expose on host port 5433 to avoid conflict
    environment:
      - POSTGRES_USER=etl_user
      - POSTGRES_PASSWORD=etl_pass
      - POSTGRES_DB=etl_db
    volumes:
      - etl-db-data:/var/lib/postgresql/data
    networks:
      - airflow_network
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "etl_user"]
      interval: 5s
      timeout: 5s
      retries: 5

  # Airflow Webserver and Scheduler (running in one container for simplicity)
  # For production, you'd split webserver and scheduler into separate services
  airflow-services:
    <<: *airflow-common
    container_name: airflow_services
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 10s
      timeout: 10s
      retries: 3

volumes:
  airflow-db-data:
  etl-db-data:

networks:
  airflow_network:
    driver: bridge